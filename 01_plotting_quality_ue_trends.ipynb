{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_dict = {\n",
    "    'MaximumSequenceProbability': 'MSP',\n",
    "    'Perplexity': 'PPL',\n",
    "    'MeanTokenEntropy': 'MTE',\n",
    "    'MonteCarloSequenceEntropy': 'MCSE',\n",
    "    'MonteCarloNormalizedSequenceEntropy': 'MCNSE',\n",
    "        'LexicalSimilarity_rougeL': 'LSRL',\n",
    "        'TokenSAR':'TokenSAR'\n",
    "\n",
    "}\n",
    "\n",
    "DATASETS_MT = [\n",
    "    'wmt14_deen',\n",
    "    'wmt14_fren',\n",
    "    'wmt14_csen',\n",
    "    'wmt14_ruen',\n",
    "    'wmt19_ruen',\n",
    "    'wmt19_fien',\n",
    "    'wmt19_deen',\n",
    "    'wmt19_lten'\n",
    "]\n",
    "\n",
    "all_metrics_mt = ['Comet-wmt22-comet-da', 'XComet-XCOMET-XXL', 'metricx-metricx-24-hybrid-large-v2p6']\n",
    "all_methods =['MSP', 'PPL', 'MTE', 'MCSE', 'MCNSE', 'LSRL','TokenSAR']\n",
    "\n",
    "\n",
    "metrics_dict ={\n",
    "  'Comet':'Comet', 'XComet-XCOMET-XXL' :'XComet-XXL', 'metricx-metricx-24-hybrid-large-v2p6' :'MetricX-Large' ,\n",
    "  'AlignScoreInputOutput':'Align Score', 'Accuracy':'Acc', 'AlignScoreInputOutput':'Align Score','Rouge_rougeL':'Rouge L', 'Comet-wmt22-comet-da':'Comet',\n",
    "    'MSP':'MSP', 'PPL' :'PPL', 'MTE' :'MTE',  'MCSE':'MCSE', 'MCNSE':'MCNSE', 'LSRL': 'LSRL','TokenSAR':'TokenSAR'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import linregress\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "sns.set(style=\"whitegrid\", font_scale=1.4, rc={\"font.family\": \"serif\"})\n",
    "\n",
    "\n",
    "def format_dataset_name(raw_name):\n",
    "    try:\n",
    "        prefix, lang_pair = raw_name.split(\"_\")\n",
    "        prefix = prefix.upper()\n",
    "\n",
    "        if len(lang_pair) == 4:  # e.g., fren â†’ Fr-En\n",
    "            src = lang_pair[:2].capitalize()\n",
    "            tgt = lang_pair[2:].capitalize()\n",
    "            lang_fmt = f\"{src}-{tgt}\"\n",
    "        else:\n",
    "            lang_fmt = lang_pair.upper()\n",
    "\n",
    "        return f\"{prefix} {lang_fmt}\"\n",
    "    except Exception:\n",
    "        return raw_name.upper()\n",
    "\n",
    "\n",
    "def plot_metric_vs_length(\n",
    "    gen_lengths, metric_values,\n",
    "    metric_name, dataset_name, save_path='plot.pdf', model='llama', task ='nmt'\n",
    "):\n",
    "\n",
    "    # Trim outliers\n",
    "    upper_q, lower_q = np.quantile(gen_lengths, [0.95, 0.05])\n",
    "    mask = (gen_lengths > lower_q) & (gen_lengths < upper_q)\n",
    "    gen_lengths = gen_lengths[mask]\n",
    "    metric_values = metric_values[mask]\n",
    "\n",
    "    # Normalize\n",
    "    scaler_len = MinMaxScaler()\n",
    "    scaler_val = MinMaxScaler()\n",
    "\n",
    "    norm_len = scaler_len.fit_transform(gen_lengths[:, None]).squeeze()\n",
    "    norm_val = scaler_val.fit_transform(metric_values[:, None]).squeeze()\n",
    "\n",
    "    # Bin and smooth\n",
    "    df = pd.DataFrame({\"length\": norm_len, \"metric\": norm_val})\n",
    "    grouped = df.groupby(\"length\").agg(['mean', 'sem'])\n",
    "    x_vals = grouped.index.values\n",
    "    y_vals = grouped['metric']['mean'].values\n",
    "    y_errs = grouped['metric']['sem'].values\n",
    "\n",
    "    # Fit regression (on raw normalized data)\n",
    "    linreg = LinearRegression().fit(norm_len[:, None], norm_val)\n",
    "    slope = linreg.coef_[0]\n",
    "\n",
    "    # Compute p-value\n",
    "    slope_, intercept_, r_val, p_val, std_err = linregress(norm_len, norm_val)\n",
    "\n",
    "    x_line = np.linspace(0, 1, 100)\n",
    "    y_line = linreg.predict(x_line[:, None])\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.plot(x_vals, y_vals, label='AVG metric value', color=\"navy\")\n",
    "    ax.fill_between(x_vals, y_vals - y_errs, y_vals + y_errs, alpha=0.2, color=\"navy\")\n",
    "    ax.plot(x_line, y_line, linestyle='--', color='crimson', label='Regression Line')\n",
    "\n",
    "\n",
    "    if task=='nmt':\n",
    "        pretty_dataset = format_dataset_name(dataset_name)\n",
    "    else:\n",
    "        pretty_dataset = dataset_name.capitalize()\n",
    "    ax.set_title(f\"{metrics_dict[metric_name]} vs. Length ({pretty_dataset})\", fontsize=14)\n",
    "    ax.set_xlabel(\"Generated sequence length (normalized)\")\n",
    "    ax.set_ylabel(f\"{metrics_dict[metric_name]} (normalized)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric trends plots (Translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from utils import extract_and_prepare_data\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "models =['llama','gemma','eurollm']\n",
    "for model in models:\n",
    "    for dataset in DATASETS_MT:\n",
    "        train_ue_values, test_ue_values, train_metric_values, test_metric_values, train_gen_lengths, gen_lengths = extract_and_prepare_data(dataset, methods_dict, all_metrics_mt, model=model)\n",
    "\n",
    "        for metric in all_metrics_mt:\n",
    "            os.makedirs(f'plots', exist_ok=True)\n",
    "\n",
    "            plot_metric_vs_length(\n",
    "                gen_lengths=np.array(train_gen_lengths),\n",
    "                metric_values=np.array(train_metric_values[metric]),\n",
    "                metric_name=metric,\n",
    "                dataset_name=dataset,\n",
    "                save_path=f'plots/{model}_{dataset}_{metric}_train.pdf',\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric trends plots (Summarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "DATASETS_SUM =['xsum']\n",
    "all_metrics_sum = ['AlignScoreInputOutput']\n",
    "models_sum =['llama','gemma']\n",
    "\n",
    "for model in models_sum:\n",
    "    for dataset in DATASETS_SUM:\n",
    "        train_ue_values, test_ue_values, train_metric_values, test_metric_values, train_gen_lengths, gen_lengths = extract_and_prepare_data(dataset, methods_dict, all_metrics_sum, model=model)\n",
    "\n",
    "        for metric in all_metrics_sum:\n",
    "            os.makedirs(f'plots', exist_ok=True)\n",
    "\n",
    "            plot_metric_vs_length(\n",
    "                gen_lengths=np.array(train_gen_lengths),\n",
    "                metric_values=np.array(train_metric_values[metric]),\n",
    "                metric_name=metric,\n",
    "                dataset_name=dataset,\n",
    "                save_path=f'plots/{dataset}_{metric}_{model}_train.pdf',\n",
    "                task='sum'\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric trends plots (Mathematical Reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import os \n",
    "DATASETS_MR =['gsm8k']\n",
    "all_metrics_mr=['Accuracy']\n",
    "models_mr =['llama','gemma']\n",
    "for model in models_mr:\n",
    "    for dataset in DATASETS_MR:\n",
    "        train_ue_values, test_ue_values, train_metric_values, test_metric_values, train_gen_lengths, gen_lengths = extract_and_prepare_data(dataset, methods_dict, all_metrics_mr, model=model)\n",
    "\n",
    "        for metric in all_metrics_mr:\n",
    "            os.makedirs(f'plots', exist_ok=True)\n",
    "\n",
    "            plot_metric_vs_length(\n",
    "                gen_lengths=np.array(train_gen_lengths),\n",
    "                metric_values=np.array(train_metric_values[metric]),\n",
    "                metric_name=metric,\n",
    "                dataset_name=dataset,\n",
    "                save_path=f'plots/{dataset}_{metric}_{model}_train.pdf',\n",
    "                task='mr'\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UE metrics trends (Translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "methods_dict = {\n",
    "    'MaximumSequenceProbability': 'MSP',\n",
    "    'Perplexity': 'PPL',\n",
    "    'MeanTokenEntropy': 'MTE',\n",
    "    'MonteCarloSequenceEntropy': 'MCSE',\n",
    "    'MonteCarloNormalizedSequenceEntropy': 'MCNSE',\n",
    "    'LexicalSimilarity_rougeL': 'LSRL',\n",
    "    'TokenSAR':'TokenSAR'\n",
    "}\n",
    "\n",
    "for model in models:\n",
    "    for dataset in DATASETS_MT:\n",
    "        train_ue_values, test_ue_values, train_metric_values, test_metric_values, train_gen_lengths, gen_lengths = extract_and_prepare_data(dataset, methods_dict, all_metrics_mt, model=model)\n",
    "        \n",
    "        for metric, metric_short  in methods_dict.items():\n",
    "            os.makedirs(f'plots', exist_ok=True)\n",
    "            plot_metric_vs_length(\n",
    "                gen_lengths=np.array(train_gen_lengths),\n",
    "                metric_values=np.array(train_ue_values[metric_short]),\n",
    "                metric_name=metric_short,\n",
    "                dataset_name=dataset,\n",
    "                save_path=f'plots/{dataset}_{metric}_{model}_train.pdf',\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UE metrics trends (Summarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for model in models_sum:\n",
    "    for dataset in DATASETS_SUM:\n",
    "        train_ue_values, test_ue_values, train_metric_values, test_metric_values, train_gen_lengths, gen_lengths = extract_and_prepare_data(dataset, methods_dict, all_metrics_sum, model=model)\n",
    "\n",
    "        for metric, metric_short  in methods_dict.items():\n",
    "            os.makedirs(f'plots', exist_ok=True)\n",
    "            plot_metric_vs_length(\n",
    "                gen_lengths=np.array(train_gen_lengths),\n",
    "                metric_values=np.array(train_ue_values[metric_short]),\n",
    "                metric_name=metric_short,\n",
    "                dataset_name=dataset,\n",
    "                save_path=f'plots/{dataset}_{metric}_{model}_train.pdf',\n",
    "                task='sum'\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UE metrics trends (Mathematical Reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for model in models_mr:\n",
    "    for dataset in DATASETS_MR:\n",
    "        train_ue_values, test_ue_values, train_metric_values, test_metric_values, train_gen_lengths, gen_lengths = extract_and_prepare_data(dataset, methods_dict, all_metrics_mr, model=model)\n",
    "\n",
    "        for metric, metric_short  in methods_dict.items():\n",
    "            os.makedirs(f'plots', exist_ok=True)\n",
    "            plot_metric_vs_length(\n",
    "                gen_lengths=np.array(train_gen_lengths),\n",
    "                metric_values=np.array(train_ue_values[metric_short]),\n",
    "                metric_name=metric_short,\n",
    "                dataset_name=dataset,\n",
    "                save_path=f'plots/{dataset}_{metric}_{model}_train.pdf',\n",
    "                task='mr'\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables with slopes and coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_dict = {\n",
    "    'MaximumSequenceProbability': 'MSP',\n",
    "    'Perplexity': 'PPL',\n",
    "    'MeanTokenEntropy': 'MTE',\n",
    "    'MonteCarloSequenceEntropy': 'MCSE',\n",
    "    'MonteCarloNormalizedSequenceEntropy': 'MCNSE',\n",
    "    'LexicalSimilarity_rougeL': 'LSRL',\n",
    "    'TokenSAR':'TokenSAR'\n",
    "}\n",
    "\n",
    "DATASETS_MT = [\n",
    "    'wmt14_deen',\n",
    "    'wmt14_fren',\n",
    "    'wmt14_csen',\n",
    "    'wmt14_ruen',\n",
    "    'wmt19_ruen',\n",
    "    'wmt19_fien',\n",
    "    'wmt19_deen',\n",
    "    'wmt19_lten'\n",
    "]\n",
    "\n",
    "all_metrics_mt = ['Comet-wmt22-comet-da', 'XComet-XCOMET-XXL', 'metricx-metricx-24-hybrid-large-v2p6']\n",
    "all_methods =['MSP', 'PPL', 'MTE', 'MCSE', 'MCNSE', 'LSRL', 'TokenSAR']\n",
    "\n",
    "\n",
    "metrics_dict ={\n",
    "  'Comet':'Comet', 'XComet-XCOMET-XXL' :'XComet-XXL', 'metricx-metricx-24-hybrid-large-v2p6' :'MetricX-Large' ,\n",
    "  'AlignScoreInputOutput':'Align Score', 'Accuracy':'Acc', 'AlignScoreInputOutput':'Align Score','Rouge_rougeL':'Rouge L', 'Comet-wmt22-comet-da':'Comet',\n",
    "    'MSP':'MSP', 'PPL' :'PPL', 'MTE' :'MTE',  'MCSE':'MCSE', 'MCNSE':'MCNSE', 'LSRL': 'LSRL'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import linregress\n",
    "\n",
    "def compute_length_metric_correlation(gen_lengths, metric_values, trim_quantiles=(0.05, 0.95)):\n",
    "    \n",
    "    gen_lengths = np.asarray(gen_lengths)\n",
    "    metric_values = np.asarray(metric_values)\n",
    "\n",
    "    # --- Trim outliers ---\n",
    "    lower_q, upper_q = np.quantile(gen_lengths, [trim_quantiles[0], trim_quantiles[1]])\n",
    "    mask = (gen_lengths > lower_q) & (gen_lengths < upper_q)\n",
    "    gen_lengths = gen_lengths[mask]\n",
    "    metric_values = metric_values[mask]\n",
    "\n",
    "    # --- Normalize ---\n",
    "    scaler_len = MinMaxScaler()\n",
    "    scaler_val = MinMaxScaler()\n",
    "    norm_len = scaler_len.fit_transform(gen_lengths[:, None]).squeeze()\n",
    "    norm_val = scaler_val.fit_transform(metric_values[:, None]).squeeze()\n",
    "\n",
    "    # --- Linear regression ---\n",
    "    linreg = LinearRegression().fit(norm_len[:, None], norm_val)\n",
    "    slope = float(linreg.coef_[0])\n",
    "\n",
    "    # SciPy linregress for p-value and correlation\n",
    "    slope_, intercept_, r_val, p_val, std_err = linregress(norm_len, norm_val)\n",
    "\n",
    "    return slope, p_val, r_val\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiya.goloburda/.conda/envs/detrend/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4e76c6da0>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4f98151e0>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiya.goloburda/.conda/envs/detrend/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4ebdc4be0>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4eb7c8a00>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiya.goloburda/.conda/envs/detrend/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4f175d780>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4e74df520>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiya.goloburda/.conda/envs/detrend/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4ea5cf6a0>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4eb6f82b0>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiya.goloburda/.conda/envs/detrend/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4eba766b0>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4f06852d0>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiya.goloburda/.conda/envs/detrend/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4e6cbf970>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4e79d8c10>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiya.goloburda/.conda/envs/detrend/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4ebb3b520>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4e79dba60>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiya.goloburda/.conda/envs/detrend/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4f100bd00>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4e79d9540>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiya.goloburda/.conda/envs/detrend/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4eba77550>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4eb208190>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiya.goloburda/.conda/envs/detrend/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4f8b0f520>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4f0452710>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiya.goloburda/.conda/envs/detrend/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4ea565060>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4e74b8700>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiya.goloburda/.conda/envs/detrend/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4eba75780>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4eb79d3c0>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiya.goloburda/.conda/envs/detrend/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4f04530a0>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4ebb3b040>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiya.goloburda/.conda/envs/detrend/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4e74bb610>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4f8b0f1f0>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiya.goloburda/.conda/envs/detrend/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4f8b0d0f0>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4f0451f60>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiya.goloburda/.conda/envs/detrend/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4f06878e0>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4f0453130>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiya.goloburda/.conda/envs/detrend/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4f0686560>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4e79d8310>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiya.goloburda/.conda/envs/detrend/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4f8b0feb0>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4eba75510>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiya.goloburda/.conda/envs/detrend/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4e6cbe620>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4f1008cd0>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiya.goloburda/.conda/envs/detrend/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4eb79c790>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4eb5d34c0>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiya.goloburda/.conda/envs/detrend/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4eb5d3790>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4ea565030>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiya.goloburda/.conda/envs/detrend/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4f0684430>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4e6cbd750>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiya.goloburda/.conda/envs/detrend/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat calculators: [<lm_polygraph.stat_calculators.greedy_probs.GreedyProbsCalculator object at 0x7ff4e74eca60>]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "methods_dict = {\n",
    "    'MaximumSequenceProbability': 'MSP',\n",
    "    'Perplexity': 'PPL',\n",
    "    'MeanTokenEntropy': 'MTE',\n",
    "    'MonteCarloSequenceEntropy': 'MCSE',\n",
    "    'MonteCarloNormalizedSequenceEntropy': 'MCNSE',\n",
    "    'LexicalSimilarity_rougeL': 'LSRL',\n",
    "    'TokenSAR':'TokenSAR'\n",
    "}\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "rows = []  \n",
    "\n",
    "for model in models:\n",
    "    for dataset in DATASETS_MT:\n",
    "        (train_ue_values, test_ue_values,\n",
    "         train_metric_values, test_metric_values,\n",
    "         train_gen_lengths, gen_lengths) = extract_and_prepare_data(\n",
    "            dataset, methods_dict, all_metrics_mt, model=model\n",
    "        )\n",
    "\n",
    "        for long_name, short_name in methods_dict.items():\n",
    "            slope, p_val, r_val = compute_length_metric_correlation(\n",
    "                gen_lengths=np.array(train_gen_lengths),\n",
    "                metric_values=np.array(train_ue_values[short_name]),\n",
    "            )\n",
    "            rows.append({\n",
    "                \"model\": model,\n",
    "                \"dataset\": dataset,\n",
    "                \"category\": \"ue\",         \n",
    "                \"name\": short_name,        \n",
    "                \"slope\": float(slope),\n",
    "                \"p_value\": float(p_val),\n",
    "                \"r_value\": float(r_val),\n",
    "            })\n",
    "\n",
    "        for metric in all_metrics_mt:\n",
    "            slope, p_val, r_val = compute_length_metric_correlation(\n",
    "                gen_lengths=np.array(train_gen_lengths),\n",
    "                metric_values=np.array(train_metric_values[metric]),\n",
    "            )\n",
    "            rows.append({\n",
    "                \"model\": model,\n",
    "                \"dataset\": dataset,\n",
    "                \"category\": \"metric\",      # e.g., MetricX, COMET...\n",
    "                \"name\": metric,\n",
    "                \"slope\": float(slope),\n",
    "                \"p_value\": float(p_val),\n",
    "                \"r_value\": float(r_val),\n",
    "            })\n",
    "\n",
    "# Save one CSV\n",
    "df = pd.DataFrame(rows)\n",
    "out_path = \"results/length_vs_ue_corr.csv\"\n",
    "df.to_csv(out_path, index=False)\n",
    "print(f\"Wrote {out_path} with {len(df)} rows.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== eurollm ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MSP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">PPL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MTE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MCSE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MCNSE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LSRL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wmt14_csen</th>\n",
       "      <td>0.299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt14_deen</th>\n",
       "      <td>0.359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt14_fren</th>\n",
       "      <td>0.368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt14_ruen</th>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt19_deen</th>\n",
       "      <td>0.203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt19_fien</th>\n",
       "      <td>0.462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt19_lten</th>\n",
       "      <td>0.318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt19_ruen</th>\n",
       "      <td>0.451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method        MSP          PPL           MTE         MCSE        MCNSE         \\\n",
       "            slope p-val  slope  p-val  slope p-val  slope p-val  slope  p-val   \n",
       "dataset                                                                         \n",
       "wmt14_csen  0.299   0.0 -0.056  0.000 -0.091   0.0  0.424   0.0 -0.057  0.000   \n",
       "wmt14_deen  0.359   0.0 -0.083  0.000 -0.117   0.0  0.340   0.0 -0.025  0.109   \n",
       "wmt14_fren  0.368   0.0 -0.121  0.000 -0.141   0.0  0.169   0.0 -0.042  0.002   \n",
       "wmt14_ruen  0.266   0.0 -0.136  0.000 -0.195   0.0  0.227   0.0 -0.171  0.000   \n",
       "wmt19_deen  0.203   0.0 -0.043  0.002 -0.106   0.0  0.265   0.0 -0.071  0.000   \n",
       "wmt19_fien  0.462   0.0 -0.037  0.001 -0.075   0.0  0.312   0.0 -0.037  0.003   \n",
       "wmt19_lten  0.318   0.0 -0.057  0.000 -0.118   0.0  0.282   0.0 -0.070  0.000   \n",
       "wmt19_ruen  0.451   0.0 -0.083  0.000 -0.137   0.0  0.363   0.0 -0.115  0.000   \n",
       "\n",
       "Method       LSRL         \n",
       "            slope  p-val  \n",
       "dataset                   \n",
       "wmt14_csen -0.014  0.426  \n",
       "wmt14_deen  0.011  0.553  \n",
       "wmt14_fren  0.000  0.988  \n",
       "wmt14_ruen -0.164  0.000  \n",
       "wmt19_deen -0.015  0.433  \n",
       "wmt19_fien  0.048  0.009  \n",
       "wmt19_lten  0.023  0.232  \n",
       "wmt19_ruen -0.092  0.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== gemma ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MSP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">PPL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MTE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MCSE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MCNSE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LSRL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wmt14_csen</th>\n",
       "      <td>0.551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt14_deen</th>\n",
       "      <td>0.395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt14_fren</th>\n",
       "      <td>0.485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt14_ruen</th>\n",
       "      <td>0.377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt19_deen</th>\n",
       "      <td>0.376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt19_fien</th>\n",
       "      <td>0.506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.790</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt19_lten</th>\n",
       "      <td>0.567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt19_ruen</th>\n",
       "      <td>0.631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method        MSP          PPL           MTE         MCSE        MCNSE         \\\n",
       "            slope p-val  slope  p-val  slope p-val  slope p-val  slope  p-val   \n",
       "dataset                                                                         \n",
       "wmt14_csen  0.551   0.0 -0.049  0.000 -0.100   0.0  0.587   0.0  0.017  0.226   \n",
       "wmt14_deen  0.395   0.0 -0.076  0.000 -0.118   0.0  0.486   0.0  0.009  0.526   \n",
       "wmt14_fren  0.485   0.0 -0.088  0.000 -0.138   0.0  0.567   0.0 -0.052  0.000   \n",
       "wmt14_ruen  0.377   0.0 -0.175  0.000 -0.236   0.0  0.485   0.0 -0.137  0.000   \n",
       "wmt19_deen  0.376   0.0 -0.029  0.008 -0.092   0.0  0.322   0.0 -0.028  0.029   \n",
       "wmt19_fien  0.506   0.0 -0.004  0.790 -0.057   0.0  0.507   0.0  0.003  0.836   \n",
       "wmt19_lten  0.567   0.0 -0.019  0.029 -0.065   0.0  0.398   0.0  0.001  0.962   \n",
       "wmt19_ruen  0.631   0.0 -0.055  0.000 -0.106   0.0  0.591   0.0 -0.066  0.000   \n",
       "\n",
       "Method       LSRL         \n",
       "            slope  p-val  \n",
       "dataset                   \n",
       "wmt14_csen  0.045  0.001  \n",
       "wmt14_deen  0.046  0.001  \n",
       "wmt14_fren  0.028  0.035  \n",
       "wmt14_ruen -0.167  0.000  \n",
       "wmt19_deen  0.048  0.001  \n",
       "wmt19_fien  0.085  0.000  \n",
       "wmt19_lten  0.090  0.000  \n",
       "wmt19_ruen -0.025  0.084  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== llama ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MSP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">PPL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MTE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MCSE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MCNSE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LSRL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wmt14_csen</th>\n",
       "      <td>0.467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt14_deen</th>\n",
       "      <td>0.445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt14_fren</th>\n",
       "      <td>0.519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt14_ruen</th>\n",
       "      <td>0.329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt19_deen</th>\n",
       "      <td>0.447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt19_fien</th>\n",
       "      <td>0.478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt19_lten</th>\n",
       "      <td>0.426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt19_ruen</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method        MSP          PPL          MTE         MCSE        MCNSE         \\\n",
       "            slope p-val  slope p-val  slope p-val  slope p-val  slope  p-val   \n",
       "dataset                                                                        \n",
       "wmt14_csen  0.467   0.0 -0.070  0.00 -0.083   0.0  0.449   0.0 -0.004  0.757   \n",
       "wmt14_deen  0.445   0.0 -0.076  0.00 -0.113   0.0  0.428   0.0 -0.006  0.666   \n",
       "wmt14_fren  0.519   0.0 -0.079  0.00 -0.102   0.0  0.477   0.0 -0.048  0.000   \n",
       "wmt14_ruen  0.329   0.0 -0.069  0.00 -0.118   0.0  0.387   0.0 -0.088  0.000   \n",
       "wmt19_deen  0.447   0.0 -0.046  0.00 -0.130   0.0  0.315   0.0 -0.025  0.064   \n",
       "wmt19_fien  0.478   0.0 -0.014  0.15 -0.077   0.0  0.385   0.0 -0.004  0.736   \n",
       "wmt19_lten  0.426   0.0 -0.046  0.00 -0.081   0.0  0.453   0.0 -0.005  0.734   \n",
       "wmt19_ruen  0.455   0.0 -0.090  0.00 -0.142   0.0  0.357   0.0 -0.098  0.000   \n",
       "\n",
       "Method       LSRL         \n",
       "            slope  p-val  \n",
       "dataset                   \n",
       "wmt14_csen  0.046  0.002  \n",
       "wmt14_deen  0.059  0.000  \n",
       "wmt14_fren  0.047  0.001  \n",
       "wmt14_ruen -0.153  0.000  \n",
       "wmt19_deen  0.087  0.000  \n",
       "wmt19_fien  0.081  0.000  \n",
       "wmt19_lten  0.086  0.000  \n",
       "wmt19_ruen -0.062  0.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV\n",
    "corr = pd.read_csv(\"results/length_vs_ue_corr.csv\")\n",
    "\n",
    "method_order = list(methods_dict.values())  \n",
    "corr_ue = corr[corr[\"category\"] == \"ue\"].copy()\n",
    "\n",
    "piv_slope = corr_ue.pivot_table(index=[\"model\", \"dataset\"], columns=\"name\", values=\"slope\", aggfunc=\"first\")\n",
    "piv_pval  = corr_ue.pivot_table(index=[\"model\", \"dataset\"], columns=\"name\", values=\"p_value\", aggfunc=\"first\")\n",
    "\n",
    "piv_slope = piv_slope.reindex(columns=method_order)\n",
    "piv_pval  = piv_pval.reindex(columns=method_order)\n",
    "\n",
    "cols = []\n",
    "parts = []\n",
    "for m in method_order:\n",
    "    cols.extend([(m, \"slope\"), (m, \"p-val\")])\n",
    "    parts.append(piv_slope[m])\n",
    "    parts.append(piv_pval[m])\n",
    "\n",
    "table = pd.concat(parts, axis=1)\n",
    "table.columns = pd.MultiIndex.from_tuples(cols, names=[\"Method\", \"\"])\n",
    "\n",
    "table = table.round({col: 3 for col in table.columns})  \n",
    "\n",
    "for model_name in table.index.get_level_values(\"model\").unique():\n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    display(table.loc[model_name])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== eurollm ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MetricX XXL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">XComet XXL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Comet WMT22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wmt14_csen</th>\n",
       "      <td>0.027</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.572</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt14_deen</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.929</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt14_fren</th>\n",
       "      <td>0.007</td>\n",
       "      <td>0.666</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.152</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt14_ruen</th>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt19_deen</th>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt19_fien</th>\n",
       "      <td>0.104</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt19_lten</th>\n",
       "      <td>0.026</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt19_ruen</th>\n",
       "      <td>0.049</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metric     MetricX XXL        XComet XXL        Comet WMT22       \n",
       "                 slope  p-val      slope  p-val       slope  p-val\n",
       "dataset                                                           \n",
       "wmt14_csen       0.027  0.040     -0.011  0.572      -0.047  0.001\n",
       "wmt14_deen       0.002  0.929     -0.035  0.157      -0.016  0.413\n",
       "wmt14_fren       0.007  0.666     -0.034  0.152      -0.029  0.042\n",
       "wmt14_ruen      -0.058  0.001     -0.031  0.250      -0.101  0.000\n",
       "wmt19_deen      -0.050  0.000     -0.096  0.000      -0.156  0.000\n",
       "wmt19_fien       0.104  0.000      0.170  0.000       0.007  0.648\n",
       "wmt19_lten       0.026  0.078      0.156  0.000      -0.027  0.053\n",
       "wmt19_ruen       0.049  0.000      0.135  0.000      -0.034  0.003"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== gemma ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MetricX XXL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">XComet XXL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Comet WMT22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wmt14_csen</th>\n",
       "      <td>0.035</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt14_deen</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.936</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt14_fren</th>\n",
       "      <td>0.016</td>\n",
       "      <td>0.302</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt14_ruen</th>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.404</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt19_deen</th>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt19_fien</th>\n",
       "      <td>0.074</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt19_lten</th>\n",
       "      <td>0.022</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt19_ruen</th>\n",
       "      <td>0.049</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metric     MetricX XXL        XComet XXL        Comet WMT22       \n",
       "                 slope  p-val      slope  p-val       slope  p-val\n",
       "dataset                                                           \n",
       "wmt14_csen       0.035  0.013     -0.047  0.018      -0.033  0.018\n",
       "wmt14_deen       0.001  0.936     -0.053  0.027      -0.023  0.251\n",
       "wmt14_fren       0.016  0.302     -0.051  0.035      -0.028  0.048\n",
       "wmt14_ruen      -0.046  0.010     -0.021  0.404      -0.103  0.000\n",
       "wmt19_deen      -0.046  0.000     -0.095  0.000      -0.154  0.000\n",
       "wmt19_fien       0.074  0.000      0.121  0.000      -0.006  0.647\n",
       "wmt19_lten       0.022  0.178      0.110  0.000      -0.022  0.108\n",
       "wmt19_ruen       0.049  0.000      0.120  0.000      -0.034  0.004"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== llama ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MetricX XXL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">XComet XXL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Comet WMT22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "      <th>slope</th>\n",
       "      <th>p-val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wmt14_csen</th>\n",
       "      <td>0.026</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.092</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt14_deen</th>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.977</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt14_fren</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.534</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt14_ruen</th>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.272</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt19_deen</th>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt19_fien</th>\n",
       "      <td>0.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt19_lten</th>\n",
       "      <td>0.030</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmt19_ruen</th>\n",
       "      <td>0.044</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metric     MetricX XXL        XComet XXL        Comet WMT22       \n",
       "                 slope  p-val      slope  p-val       slope  p-val\n",
       "dataset                                                           \n",
       "wmt14_csen       0.026  0.071     -0.033  0.092      -0.032  0.019\n",
       "wmt14_deen      -0.001  0.977     -0.073  0.004      -0.027  0.176\n",
       "wmt14_fren       0.010  0.534     -0.077  0.002      -0.043  0.002\n",
       "wmt14_ruen      -0.028  0.130     -0.029  0.272      -0.100  0.000\n",
       "wmt19_deen      -0.057  0.000     -0.118  0.000      -0.176  0.000\n",
       "wmt19_fien       0.054  0.001      0.067  0.005      -0.016  0.288\n",
       "wmt19_lten       0.030  0.085      0.093  0.000      -0.018  0.223\n",
       "wmt19_ruen       0.044  0.001      0.090  0.000      -0.030  0.011"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "corr = pd.read_csv(\"results/length_vs_ue_corr.csv\")\n",
    "\n",
    "METRICS_PRETTY = {\n",
    "    \"metricx-metricx-24-hybrid-large-v2p6\": \"MetricX XXL\",\n",
    "    \"XComet-XCOMET-XXL\": \"XComet XXL\",\n",
    "    \"Comet-wmt22-comet-da\": \"Comet WMT22\",\n",
    "}\n",
    "corr[\"metric_pretty\"] = corr[\"name\"].map(METRICS_PRETTY).fillna(corr[\"name\"])\n",
    "\n",
    "corr_metrics = corr[corr[\"category\"] == \"metric\"].copy()\n",
    "\n",
    "if METRICS_PRETTY:\n",
    "    metric_order = [METRICS_PRETTY[k] for k in METRICS_PRETTY if k in corr[\"name\"].unique()]\n",
    "else:\n",
    "    metric_order = sorted(corr_metrics[\"metric_pretty\"].unique())\n",
    "\n",
    "piv_slope = corr_metrics.pivot_table(\n",
    "    index=[\"model\", \"dataset\"], columns=\"metric_pretty\", values=\"slope\", aggfunc=\"first\"\n",
    ").reindex(columns=metric_order)\n",
    "\n",
    "piv_pval = corr_metrics.pivot_table(\n",
    "    index=[\"model\", \"dataset\"], columns=\"metric_pretty\", values=\"p_value\", aggfunc=\"first\"\n",
    ").reindex(columns=metric_order)\n",
    "\n",
    "cols = []\n",
    "parts = []\n",
    "for m in metric_order:\n",
    "    cols.extend([(m, \"slope\"), (m, \"p-val\")])\n",
    "    parts.append(piv_slope[m])\n",
    "    parts.append(piv_pval[m])\n",
    "\n",
    "metric_table = pd.concat(parts, axis=1)\n",
    "metric_table.columns = pd.MultiIndex.from_tuples(cols, names=[\"Metric\", \"\"])\n",
    "metric_table = metric_table.round(3)\n",
    "\n",
    "# Show one block per model (rows = datasets)\n",
    "for model_name in metric_table.index.get_level_values(\"model\").unique():\n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    display(metric_table.loc[model_name])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detrend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
